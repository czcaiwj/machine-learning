# 第6周 机器学习的最佳实践

## 一、评估假设函数

如果我们的假设函数不理想，我们通常会：

+ 想办法获取更多的训练样本
+ 缩小特征集
+ 添加额外特征
+ 尝试多项式特征
+ 增加或减小正规化$\lambda$参数

假设函数可能对训练集来说有很小的误差，但仍可能是不准确的，因为有可能存在过拟合的情况。因此，要评价一个假设函数，我们可以把样本分为两部分：训练集和测试集。一般来说，训练集占样本的70%，测试集占30%。

于是过程变成：

1. 使用训练集来得到$\Theta$和最小化$J_{train}(\Theta)$。
2. 使用测试集来计算$J_{test}(\Theta)$的误差。

### 1.1 测试集误差

1. 对线性回归来说
   $$
   J_{test}(\Theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_\Theta(x^{(i)}_{test})-y_{test}^{(i)})^2
   $$

2. 对分类问题来说，分类错误（0/1分类错误）可以表示为：
   $$
   err(h_\Theta(x),y) = \begin{cases}\begin{matrix} 1 & \mbox{if } h_\Theta(x) \geq 0.5\ and\ y = 0\ or\ h_\Theta(x) < 0.5\ and\ y = 1\newline 0 & \mbox {if } h_\Theta(x) \geq 0.5\ and\ y = 1\ or\ h_\Theta(x) < 0.5\ and\ y = 0 \end{matrix}\end{cases}
   $$
   

   那么错误的分类会标记为1，正确分类标记为0，总体的误差为：
   $$
   Test\ Error=\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}err(h_\Theta(x_{test}^{(i)}),y^{(i)}_{test})
   $$
   这就给了我们错误分类的测试数据的比例。

## 二、模型选择和训练、验证、测试集

算法能很好的拟合训练集并不一定意味着这是一个好的假设函数。因为它可能过拟合了，在训练集上的效果好，但在测试集上效果不好。从训练集上得到的函数参数的误差会比在测试集上要小。

通过给定不同的多项式度的模型，我们可以使用查看误差结果的系统方法来确定最佳函数（即确定多项式的最高次幂）。

我们可以把数据集分成3部分：

1. 训练集占60%
2. 交叉验证集占20%
3. 测试集占20%

现在可以用这三个不同的数据集来计算三个不同的误差：

1. 利用训练集最优化不同多项式维度的$\Theta$
2. 利用交叉验证集确定误差最小的那个多项式，确定多项式的幂次
3. 利用测试集来计算模型的泛化误差

通过这样的方式，多项式的维度d就不会过拟合测试集了。

## 三、偏差和方差

多项式的幂（次数）和假设函数欠拟合或过拟合之间的关系：

+ 需要区分是偏差（bias）还是方差（variance）哪一个导致假设函数无法正确预测。
+ 高偏差将导致欠拟合，高方差将导致过拟合。理想情况下，我们需要找到这两者之间的最佳平衡点。

随着多项式次数的增加，训练集的误差会减小。

同时，交叉验证集的误差会逐渐减小，但当到达某一点后，误差会逐渐增加，其图像就类似于凸函数。

+ 高偏差（欠拟合）：训练集$J_{train}(\Theta)$和交叉验证集$J_{CV}(\Theta)$的误差都会大，同时$J_{train}(\Theta)\approx J_{CV}(\Theta)$。
+ 高方差（过拟合）：训练集$J_{train}(\Theta)$误差会很小，而交叉验证集$J_{CV}(\Theta)$误差会很大，且$J_{CV}(\Theta)$要远大于$J_{train}(\Theta)$。

![偏差与方差](第6周 机器学习的应用建议.assets/偏差与方差.png)

## 四、正则化与偏差和方差的关系

当$\lambda$很大的时候，在代价函数的约束下，各个参数系数会被压缩得很小，发挥作用的只有$\theta_0$，此时假设函数的图像类似一条直线，即欠拟合（高偏差）。

当$\lambda$很小的时候，可以认为其没有发挥作用，此时假设函数会过拟合（高方差）。

如何选择恰当的$\lambda$，我们需要：

1. 创建一个$\lambda$选项列表，如$\lambda\in(0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24)$。
2. 创建一组不同幂次的多项式或任何其他变体的模型。
3. 迭代所有$\lambda$值到不同模型中，得到相应的$\Theta$。
4. 使用交叉验证集的数据去计算其误差$J_{CV}(\Theta)$。注意这一步不需要引入$\lambda$。
5. 选择在交叉验证集上产生最小误差的最佳$\Theta、\lambda$组合。
6. 使用该最佳$\Theta、\lambda$组合去测试集上计算，看是否有很好的泛化能力。

## 五、学习曲线

使用很少的数据来训练模型通常可以达到0误差，因为我们始终可以找到相应的多项式方程来拟合这几个数据点。因此：

+ 随着训练集数据的增加，多项式的误差跟着增加。
+ 误差值将在数据量达到一定程度后趋于平稳。

### 5.1 高偏差

+ 数据量少的情况下：$J_{train}(\Theta)$小，$J_{CV}(\Theta)$大。
+ 数据量多的情况下，$J_{train}(\Theta)$大，$J_{CV}(\Theta)$大，且$J_{train}(\Theta)\approx J_{CV}(\Theta)$。

如果学习算法存在**高偏差**的话，那么**增加**训练的数据量**没有多大帮助**。

![高偏差下的学习曲线](第6周 机器学习的应用建议.assets/高偏差下的学习曲线.png)

### 5.2 高方差

+ 数据量少的情况下：$J_{train}(\Theta)$小，$J_{CV}(\Theta)$大。
+ 数据量多的情况下：$J_{train}(\Theta)$随着训练集数据量的增加而增加，$J_{CV}(\Theta)$持续下降。同时，$J_{train}(\Theta)\lt J_{CV}(\Theta)$，且它们之间的差异仍然很大。

如果学习算法存在**高方差**的话，那么增加训练的数据量将**有所帮助**。

![高方差下的学习曲线](第6周 机器学习的应用建议.assets/高方差下的学习曲线.png)

## 六、下一步该怎么优化

